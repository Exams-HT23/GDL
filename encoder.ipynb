{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "2b85730d",
      "metadata": {},
      "source": [
        "# Geometric Deep Learning\n",
        "*Hilary Term 2023*\n",
        "\n",
        "---\n",
        "This notebook conducts a number of experiments to validate the claim that the removal of the encoder in the Gradient Flow Framework (GRAFF) does not significantly diminish performance."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "yCQ1EheQsrRc",
      "metadata": {
        "id": "yCQ1EheQsrRc"
      },
      "source": [
        "Run the cell below to install the necessary dependencies for this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "bo8tgBVc040C",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "bo8tgBVc040C",
        "outputId": "ac92823a-79a9-4e33-9880-d671b5103791"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/, https://download.pytorch.org/whl/cu113\n",
            "Collecting torch==1.12.1+cu113\n",
            "  Downloading https://download.pytorch.org/whl/cu113/torch-1.12.1%2Bcu113-cp39-cp39-linux_x86_64.whl (1837.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 GB\u001b[0m \u001b[31m983.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.13.1+cu113\n",
            "  Downloading https://download.pytorch.org/whl/cu113/torchvision-0.13.1%2Bcu113-cp39-cp39-linux_x86_64.whl (23.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.4/23.4 MB\u001b[0m \u001b[31m66.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchaudio==0.12.1\n",
            "  Downloading https://download.pytorch.org/whl/cu113/torchaudio-0.12.1%2Bcu113-cp39-cp39-linux_x86_64.whl (3.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m93.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch==1.12.1+cu113) (4.5.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.9/dist-packages (from torchvision==0.13.1+cu113) (8.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torchvision==0.13.1+cu113) (1.22.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torchvision==0.13.1+cu113) (2.25.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision==0.13.1+cu113) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision==0.13.1+cu113) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision==0.13.1+cu113) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision==0.13.1+cu113) (1.26.14)\n",
            "Installing collected packages: torch, torchvision, torchaudio\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.13.1+cu116\n",
            "    Uninstalling torch-1.13.1+cu116:\n",
            "      Successfully uninstalled torch-1.13.1+cu116\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.14.1+cu116\n",
            "    Uninstalling torchvision-0.14.1+cu116:\n",
            "      Successfully uninstalled torchvision-0.14.1+cu116\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 0.13.1+cu116\n",
            "    Uninstalling torchaudio-0.13.1+cu116:\n",
            "      Successfully uninstalled torchaudio-0.13.1+cu116\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.14.1 requires torch==1.13.1, but you have torch 1.12.1+cu113 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed torch-1.12.1+cu113 torchaudio-0.12.1+cu113 torchvision-0.13.1+cu113\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.2/280.2 KB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for torch-geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ogb\n",
            "  Downloading ogb-1.3.5-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 KB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3>=1.24.0 in /usr/local/lib/python3.9/dist-packages (from ogb) (1.26.14)\n",
            "Collecting outdated>=0.2.0\n",
            "  Downloading outdated-0.2.2-py2.py3-none-any.whl (7.5 kB)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from ogb) (1.12.1+cu113)\n",
            "Requirement already satisfied: tqdm>=4.29.0 in /usr/local/lib/python3.9/dist-packages (from ogb) (4.65.0)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.9/dist-packages (from ogb) (1.22.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.9/dist-packages (from ogb) (1.15.0)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.9/dist-packages (from ogb) (1.4.4)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.9/dist-packages (from ogb) (1.2.2)\n",
            "Collecting littleutils\n",
            "  Downloading littleutils-0.2.2.tar.gz (6.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: setuptools>=44 in /usr/local/lib/python3.9/dist-packages (from outdated>=0.2.0->ogb) (57.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from outdated>=0.2.0->ogb) (2.25.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=0.24.0->ogb) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=0.24.0->ogb) (2022.7.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.20.0->ogb) (3.1.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.20.0->ogb) (1.1.1)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.20.0->ogb) (1.10.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.6.0->ogb) (4.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->outdated>=0.2.0->ogb) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->outdated>=0.2.0->ogb) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests->outdated>=0.2.0->ogb) (4.0.0)\n",
            "Building wheels for collected packages: littleutils\n",
            "  Building wheel for littleutils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for littleutils: filename=littleutils-0.2.2-py3-none-any.whl size=7047 sha256=e1157bf191b6deae4176488f2cee608f01807e3c7c448be9438c9bcdea8faebc\n",
            "  Stored in directory: /root/.cache/pip/wheels/04/bb/0d/2d02ec45f29c48d6192476bfb59c5a0e64b605e7212374dd15\n",
            "Successfully built littleutils\n",
            "Installing collected packages: littleutils, outdated, ogb\n",
            "Successfully installed littleutils-0.2.2 ogb-1.3.5 outdated-0.2.2\n"
          ]
        }
      ],
      "source": [
        "!pip install torch==1.12.1+cu113 torchvision==0.13.1+cu113 torchaudio==0.12.1 --extra-index-url https://download.pytorch.org/whl/cu113\n",
        "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-1.12.1+cu113.html\n",
        "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-1.12.1+cu113.html\n",
        "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n",
        "!pip install ogb"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "f2330411",
      "metadata": {},
      "source": [
        "Run the cell below to import the necessary libraries and provided external code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "3f598dde",
      "metadata": {
        "id": "3f598dde"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "\n",
        "from typing import List, Tuple, Callable\n",
        "\n",
        "from utils import train\n",
        "from models import MLP, GCN, StandardGRAFF, get_device\n",
        "\n",
        "from torch_geometric.data.data import Data\n",
        "from torch_geometric.data.dataset import Dataset\n",
        "\n",
        "from torch_geometric.datasets import Planetoid, Coauthor\n",
        "from torch_geometric.transforms import ToUndirected, RandomNodeSplit"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "zR-NEav2G0-i",
      "metadata": {
        "id": "zR-NEav2G0-i"
      },
      "source": [
        "---\n",
        "## Datasets\n",
        "The cell below downloads the five inductive node classification datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "772ba23e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "772ba23e",
        "outputId": "5be2150e-6e1a-4a2e-eaf7-13cd3703c038"
      },
      "outputs": [],
      "source": [
        "# Load the CS and Physics co-author datasets.\n",
        "datasets = [\n",
        "    Coauthor(root='/tmp', name='CS'),\n",
        "    Coauthor(root='/tmp', name='Physics')\n",
        "]\n",
        "\n",
        "# Load the three citation network datasets: Cora, CiteSeer and PubMed.\n",
        "datasets.extend([\n",
        "    Planetoid(\n",
        "        root='/tmp', \n",
        "        name=name, \n",
        "        split='geom-gcn',\n",
        "        transform=ToUndirected()\n",
        "    ) for name in ['Cora', 'CiteSeer', 'PubMed']\n",
        "])\n",
        "\n",
        "# Extract the (single) graph from these datasets and move to GPU (if available).\n",
        "datasets = [(dataset, dataset[0].to(get_device())) for dataset in datasets]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "8SFI86IZG3pe",
      "metadata": {
        "id": "8SFI86IZG3pe"
      },
      "source": [
        "---\n",
        "## Experimental Setup\n",
        "The cell below defines the experimental setup to be run for each model type and dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "587752b4",
      "metadata": {
        "id": "587752b4"
      },
      "outputs": [],
      "source": [
        "def run_experiment(\n",
        "    datasets: List[Tuple[Dataset, Data]], \n",
        "    learning_rates: List[float], \n",
        "    model_func: Callable, \n",
        "    num_runs: int = 10) -> None:\n",
        "    \n",
        "    # Iterate over each of the given datasets.\n",
        "    for learning_rate, (dataset, data) in zip(learning_rates, datasets):\n",
        "        test_accs = []\n",
        "\n",
        "        # Iterate for the given number of runs.\n",
        "        for run in range(num_runs):\n",
        "            # Get a new model.\n",
        "            model = model_func(dataset)\n",
        "            \n",
        "            # Use a random train/validation/test split for the co-author datasets.\n",
        "            if isinstance(dataset, Coauthor):\n",
        "                RandomNodeSplit(split='train_rest', num_val=0.1, num_test=0.2)(data)\n",
        "                train_mask = data.train_mask\n",
        "                val_mask = data.val_mask\n",
        "                test_mask = data.test_mask\n",
        "            else:\n",
        "                # Use the given split for the citation datasets.\n",
        "                train_mask = data.train_mask[:, run].bool()\n",
        "                val_mask = data.val_mask[:, run].bool()\n",
        "                test_mask = data.test_mask[:, run].bool()\n",
        "\n",
        "            # Train the model and record the test accuracy.\n",
        "            test_acc = train(\n",
        "                model,\n",
        "                data.x,\n",
        "                data.y,\n",
        "                data.edge_index,\n",
        "                train_mask,\n",
        "                val_mask,\n",
        "                test_mask,\n",
        "                learning_rate,\n",
        "                verbose=False\n",
        "            )\n",
        "            test_accs.append(test_acc)\n",
        "\n",
        "        name = dataset.__class__.__name__\n",
        "        if hasattr(dataset, 'name'):\n",
        "            name += '-' + dataset.name\n",
        "\n",
        "        print(f'{name}: test_accuracy={np.mean(test_accs):.3f}±{np.std(test_accs):.3f}')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "72685c5f",
      "metadata": {
        "id": "72685c5f"
      },
      "source": [
        "---\n",
        "## Multi-layer Perceptron"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "bbd29d29",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbd29d29",
        "outputId": "e8e2c81c-563d-4f18-bd08-055a7f67b4d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Coauthor-CS: test_accuracy=0.951±0.005\n",
            "Coauthor-Physics: test_accuracy=0.960±0.003\n",
            "Planetoid-Cora: test_accuracy=0.733±0.020\n",
            "Planetoid-CiteSeer: test_accuracy=0.717±0.015\n",
            "Planetoid-PubMed: test_accuracy=0.861±0.005\n"
          ]
        }
      ],
      "source": [
        "hidden_dim = 128\n",
        "\n",
        "def model_func_mlp(dataset: Dataset) -> nn.Module:\n",
        "    return MLP(\n",
        "        dataset.num_features,\n",
        "        hidden_dim,\n",
        "        dataset.num_classes\n",
        "    )\n",
        "\n",
        "learning_rates = (0.001, 0.001, 0.001, 0.001, 0.01)\n",
        "run_experiment(datasets, learning_rates, model_func_mlp)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "702ce356",
      "metadata": {
        "id": "702ce356"
      },
      "source": [
        "---\n",
        "## Graph Convolution Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "99df76c8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99df76c8",
        "outputId": "8c27182b-af3d-4c4c-d00b-82531dafa3bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Coauthor-CS: test_accuracy=0.934±0.004\n",
            "Coauthor-Physics: test_accuracy=0.963±0.002\n",
            "Planetoid-Cora: test_accuracy=0.854±0.006\n",
            "Planetoid-CiteSeer: test_accuracy=0.728±0.015\n",
            "Planetoid-PubMed: test_accuracy=0.871±0.005\n"
          ]
        }
      ],
      "source": [
        "hidden_dim = 128\n",
        "\n",
        "def model_func_gcn(dataset: Dataset) -> nn.Module:\n",
        "    return GCN(\n",
        "        dataset.num_features,\n",
        "        hidden_dim,\n",
        "        dataset.num_classes,\n",
        "        num_gcn_layers=2\n",
        "    )\n",
        "\n",
        "learning_rates = (0.001, 0.001, 0.001, 0.001, 0.01)\n",
        "run_experiment(datasets, learning_rates, model_func_gcn)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "84a693d4",
      "metadata": {
        "id": "84a693d4"
      },
      "source": [
        "---\n",
        "## GRAFF with Encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "78fe36fd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78fe36fd",
        "outputId": "3878f647-75f9-46e1-a0e0-7a808e605bbf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Coauthor-CS: test_accuracy=0.955±0.003\n",
            "Coauthor-Physics: test_accuracy=0.971±0.002\n",
            "Planetoid-Cora: test_accuracy=0.859±0.010\n",
            "Planetoid-CiteSeer: test_accuracy=0.746±0.017\n",
            "Planetoid-PubMed: test_accuracy=0.877±0.004\n"
          ]
        }
      ],
      "source": [
        "hidden_dim = 128\n",
        "\n",
        "def model_func_encoder_graff(dataset: Dataset) -> nn.Module:\n",
        "    data = dataset[0].to(get_device())\n",
        "    return StandardGRAFF(\n",
        "        dataset.num_features,\n",
        "        hidden_dim,\n",
        "        dataset.num_classes,\n",
        "        data.edge_index,\n",
        "        data.num_nodes,\n",
        "        num_graff_layers=2,\n",
        "        use_encoder=True\n",
        "    )\n",
        "\n",
        "learning_rates = (0.001, 0.001, 0.001, 0.001, 0.01)\n",
        "run_experiment(datasets, learning_rates, model_func_encoder_graff)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "f3757b61",
      "metadata": {
        "id": "f3757b61"
      },
      "source": [
        "---\n",
        "## GRAFF without Encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "584f04b4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "584f04b4",
        "outputId": "a1e000bc-28d6-4864-b4bf-8665c356c451"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Coauthor-CS: test_accuracy=0.948±0.003\n",
            "Coauthor-Physics: test_accuracy=0.968±0.003\n",
            "Planetoid-Cora: test_accuracy=0.846±0.014\n",
            "Planetoid-CiteSeer: test_accuracy=0.755±0.017\n",
            "Planetoid-PubMed: test_accuracy=0.856±0.009\n"
          ]
        }
      ],
      "source": [
        "def model_func_no_encoder_graff(dataset: Dataset) -> nn.Module:\n",
        "    data = dataset[0].to(get_device())\n",
        "    return StandardGRAFF(\n",
        "        dataset.num_features,\n",
        "        dataset.num_features,\n",
        "        dataset.num_classes,\n",
        "        data.edge_index,\n",
        "        data.num_nodes,\n",
        "        num_graff_layers=2,\n",
        "        use_encoder=False\n",
        "    )\n",
        "\n",
        "learning_rates = (0.001, 0.001, 0.001, 0.001, 0.01)\n",
        "run_experiment(datasets, learning_rates, model_func_no_encoder_graff)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
